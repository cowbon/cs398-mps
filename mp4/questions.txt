My observation of the stream reveils that users usually say something on reddit once within each of a 5 minutes period. So in my opinion, if a user post on the same subeddit for more than three times within that long of time, we can suspect that the user is a bot.
Batch Duration is the fequency of the data being processed, Window Length is the number of the RDDs processed at the same time, and Sliding Intervel is the intervel at which the window operation is performed. 
DStream is indeed a bunch of RDD. Thus, we can use DStream to represent a series of data, and there are some windows operations which can process a continuous sequence of data at the same time. While we can only do some basic transformations on normal RDDs.
A checkpoint in Spark is used to provide a backup in order to be faulr-tolerant, so it consists of 2 types, information checkpoint and data checkpoint, which are useful in recovering. Checkpoints are required if we use stateful transformations like updateStateByKey or reduceByKeyAndWindow, or when we want to recover the driver which the application runs on.
